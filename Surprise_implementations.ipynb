{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from submission_to_surprise import *\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import *\n",
    "from surprise.prediction_algorithms import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CLEAN = 'csv/data_clean.csv'\n",
    "PATH_SAMPLE = 'csv/sampleSubmission.csv'\n",
    "PATH_SUBMISSION = 'csv/submission.csv'\n",
    "data_folder = 'csv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Item</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User  Item  Rating\n",
       "0    44     1       4\n",
       "1    61     1       3\n",
       "2    67     1       4\n",
       "3    72     1       3\n",
       "4    86     1       5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH_CLEAN)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['User', 'Item', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise algorithms comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Normal Predictor is 1.483746524138451\n",
      "RMSE for Baseline Only is 1.0007649954780635\n",
      "RMSE for k-NN Basic is 1.0240415317295288\n",
      "RMSE for k-NN with means is 1.0216516207526856\n",
      "RMSE for k-NN with ZScore is 1.0184726068301606\n",
      "RMSE for k-NN Baseline is 1.0068216570125905\n",
      "RMSE for SVD is 1.0238049285552246\n",
      "RMSE for NMF is 1.0247684552622467\n",
      "RMSE for Slope one is 1.0016787898058894\n",
      "RMSE for Co-clustering is 1.0130267733860856\n"
     ]
    }
   ],
   "source": [
    "# !!!!!!!!!!! This cell takes a very long time to run !!!!!!!!!!!\n",
    "trainset, testset = train_test_split(data, test_size=.20, random_state=2018)\n",
    "\n",
    "algos = {'Normal Predictor': NormalPredictor(),\n",
    "         'Baseline Only': BaselineOnly(bsl_options={'reg_i': 10, 'reg_u': 15, 'n_epochs': 10}, verbose=False),\n",
    "         'k-NN Basic': KNNBasic(k=60, min_k=1, sim_options={'user_based': True}, verbose=False),\n",
    "         'k-NN with means': KNNWithMeans(k=50, min_k=1, sim_options={'user_based': True}, verbose=False),\n",
    "         'k-NN with ZScore': KNNWithZScore(k=70, min_k=1, sim_options={'user_based': True}, verbose=False),\n",
    "         'k-NN Baseline': KNNBaseline(k=59, min_k=1, sim_options={'user_based': True}, verbose=False),\n",
    "         'SVD': SVD(n_factors=100, reg_bu=0.01, reg_bi=0.1, reg_pu=0.1, reg_qi=0.01, random_state=2018),\n",
    "         'NMF': NMF(n_factors=22, n_epochs=50, biased=False, reg_pu=0.06, reg_qi=0.06, reg_bu=0.02, reg_bi=0.02, lr_bu=0.005, lr_bi=0.005, init_low=0, init_high=1, random_state=2018),\n",
    "         'Slope one': SlopeOne(),\n",
    "         'Co-clustering': CoClustering(n_cltr_u=3, n_cltr_i=3, n_epochs=20, random_state=2018)}\n",
    "\n",
    "for algo in algos:\n",
    "\n",
    "    predictions = algos[algo].fit(trainset).test(testset)    \n",
    "    \n",
    "    rmse = accuracy.rmse(predictions, verbose=False)\n",
    "    print(f'RMSE for {algo} is {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertion to discrete algoithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD_discrete(SVD):\n",
    "    def estimate(self, u, i):\n",
    "        return round(SVD.estimate(self, u, i))\n",
    "    \n",
    "class BaselineOnly_discrete(BaselineOnly):\n",
    "    def estimate(self, u, i):\n",
    "        return round(BaselineOnly.estimate(self, u, i))\n",
    "\n",
    "class KNNBasic_discrete(KNNBasic):\n",
    "    def estimate(self, u, i):\n",
    "        est, details = KNNBasic.estimate(self, u, i)\n",
    "        return round(est), details\n",
    "    \n",
    "class KNNWithMeans_discrete(KNNWithMeans):\n",
    "    def estimate(self, u, i):\n",
    "        est, details = KNNWithMeans.estimate(self, u, i)\n",
    "        return round(est), details\n",
    "    \n",
    "class KNNWithZScore_discrete(KNNWithZScore):\n",
    "    def estimate(self, u, i):\n",
    "        est, details = KNNWithZScore.estimate(self, u, i)\n",
    "        return round(est), details\n",
    "    \n",
    "class KNNBaseline_discrete(KNNBaseline):\n",
    "    def estimate(self, u, i):\n",
    "        est, details = KNNBaseline.estimate(self, u, i)\n",
    "        return round(est), details\n",
    "    \n",
    "class NMF_discrete(NMF):\n",
    "    def estimate(self, u, i):\n",
    "        return round(NMF.estimate(self, u, i))\n",
    "    \n",
    "class SlopeOne_discrete(SlopeOne):\n",
    "    def estimate(self, u, i):\n",
    "        return round(SlopeOne.estimate(self, u, i))\n",
    "    \n",
    "class CoClustering_discrete(CoClustering):\n",
    "    def estimate(self, u, i):\n",
    "        return round(CoClustering.estimate(self, u, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 14.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 23.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.041615105025082\n",
      "{'bsl_options': {'reg_i': 5, 'reg_u': 10, 'n_epochs': 20}}\n"
     ]
    }
   ],
   "source": [
    "algo = BaselineOnly_discrete\n",
    "\n",
    "param_grid = {'bsl_options': {'reg_i': [5, 10, 15], 'reg_u': [5, 10, 15], 'n_epochs': [20]}}\n",
    "gs = GridSearchCV(algo, param_grid, measures=['rmse'], cv=3, joblib_verbose=2)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 20.5min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 186.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0427611697713854\n",
      "{'k': 150, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "algo = KNNBaseline_discrete\n",
    "\n",
    "param_grid = {'k': [110, 130, 150], 'verbose': [False]}\n",
    "\n",
    "gs = GridSearchCV(algo, param_grid, measures=['rmse'], cv=3, joblib_verbose=2)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0391490697728307\n",
      "{'n_factors': 40, 'random_state': 2018, 'n_epochs': 60, 'reg_all': 0.05, 'lr_all': 0.002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 29.3min finished\n"
     ]
    }
   ],
   "source": [
    "algo = SVD_discrete\n",
    "\n",
    "param_grid = {'n_factors': [40], 'random_state': [2018], 'n_epochs': [60], 'reg_all': [0.01, 0.02, 0.05], 'lr_all': [0.002]}\n",
    "#param_grid = {'n_factors': [35, 36, 37, 38, 39, 40, 42], 'random_state': [2018], 'n_epochs': [60],\n",
    "#              'reg_bu': [0.01], 'reg_bi':[0.1], 'reg_pu': [0.1], 'reg_qi': [0.01]}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(algo, param_grid, measures=['rmse'], cv=4, joblib_verbose=2)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9989  0.9968  0.9998  0.9984  0.9985  0.9985  0.0010  \n",
      "Fit time          109.10  112.82  116.07  105.20  94.76   107.59  7.37    \n",
      "Test time         4.76    3.49    5.72    3.58    3.83    4.28    0.85    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.99889983, 0.99682049, 0.99983323, 0.99843902, 0.99850137]),\n",
       " 'fit_time': (109.09758067131042,\n",
       "  112.8232307434082,\n",
       "  116.06696963310242,\n",
       "  105.20380973815918,\n",
       "  94.76237297058105),\n",
       " 'test_time': (4.75638222694397,\n",
       "  3.489480495452881,\n",
       "  5.719065189361572,\n",
       "  3.5795481204986572,\n",
       "  3.8317439556121826)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(n_factors=100, reg_bu=0.01, reg_bi=0.1, reg_pu=0.1, reg_qi=0.01)\n",
    "\n",
    "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x4806018048>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = BaselineOnly(bsl_options={'reg_i': 15, 'reg_u': 0, 'n_epochs': 200})\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, _ = get_ids_values(data_folder + 'sampleSubmission.csv')\n",
    "item, user = replace_ids_submission(ids)\n",
    "prediction = np.zeros(len(item))\n",
    "for i in range(len(prediction)):\n",
    "    prediction[i] = algo.predict(user[i], item[i], None, True, False).est\n",
    "create_csv_submission(ids, prediction, 'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
